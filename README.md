# üöÄ Projeto: Pipeline de QA Automatizado para Agentes de IA (Meta-Agente)

Este projeto √© um pipeline de automa√ß√£o ponta-a-ponta desenhado para resolver um dos maiores gargalos no desenvolvimento de Agentes de IA: **o teste manual, lento e inconsistente**.

Esta ferramenta atua como um "Meta-Agente", um sistema de IAs que testa, avalia e gera relat√≥rios de performance sobre outros agentes, garantindo qualidade e acelerando o ciclo de desenvolvimento.

### üé¨ Demonstra√ß√£o R√°pida

**Parte 1: Gera√ß√£o dos Testes e Execu√ß√£o da Simula√ß√£o: https://www.loom.com/share/9ebde053df9e48d79ae143305faf2299**
**Parte 2: An√°lise, Relat√≥rio e Score Final: https://www.loom.com/share/96794539c87b4d9491396bd65eef76c0**

---

## 1. O Problema (A Dor)

Testar agentes de IA (chatbots, assistentes de vendas, etc.) √© um processo complexo:
* **Demorado:** Requer que um humano crie dezenas de cen√°rios e prompts manualmente.
* **Inconsistente:** Um testador humano pode avaliar de forma diferente de outro, ou esquecer de testar "casos extremos" (edge cases).
* **Superficial:** √â dif√≠cil para um humano simular 20 testes diferentes e depois analisar *padr√µes de erro* entre todas as conversas.

O resultado √© que gast√°vamos horas em testes manuais para cada pequena altera√ß√£o, e mesmo assim, bugs passavam para a produ√ß√£o.

## 2. A Solu√ß√£o (O Rem√©dio)

Para resolver isso, constru√≠ um **pipeline de 3 est√°gios** no n8n que gerencia o ciclo de QA de forma 100% aut√¥noma.

O sistema √© acionado por um formul√°rio, onde o desenvolvedor apenas fornece o "contexto" do que deve ser testado. A partir da√≠, o pipeline:
1.  **Cria** uma bateria de testes complexos.
2.  **Executa** cada teste simulando um usu√°rio real.
3.  **Avalia** individualmente cada conversa.
4.  **Consolida** todas as avalia√ß√µes em um relat√≥rio final com score (0-100) e an√°lise de padr√µes.

**Principais Vantagens:**
* **Economia Dr√°stica de Tempo:** Reduz o tempo de teste de horas para minutos.
* **Consist√™ncia Total:** Todos os testes s√£o gerados e avaliados com os mesmos crit√©rios rigorosos.
* **An√°lise Profunda:** O "Agente Gerente" final identifica padr√µes de erro que um humano jamais veria analisando individualmente.
* **Recurso de Depura√ß√£o (Re-teste):** O fluxo permite que o desenvolvedor escolha entre "Gerar novos testes" ou **"Repetir os mesmos testes"**. Isso √© crucial para depurar (debugar) um agente, permitindo rodar a mesma bateria de testes ap√≥s uma corre√ß√£o para verificar se o bug foi resolvido.

---

## 3. Arquitetura da Solu√ß√£o (Como Funciona)

O sistema √© composto por 3 workflows independentes no n8n que s√£o acionados em sequ√™ncia por webhooks.

### Est√°gio 1: Agente Criador de Testes
Este workflow √© o ponto de partida.
1.  **Gatilho:** Um formul√°rio (`On form submission`) ou Webhook. O dev insere o `System prompt` (contexto do teste), a `URL da planilha` e o `Path do webhook` do agente-alvo.
2.  **Sele√ß√£o de Modo (IF):** O dev escolhe "Novo teste" ou "Repete o mesmo".
    * **Se "Novo teste":** O workflow apaga os dados de *todas* as planilhas (testes antigos e resultados antigos).
    * **Se "Repete o mesmo":** O workflow apaga *apenas* os resultados antigos ("An√°lises", "Revis√£o", "Resultado"), preservando os testes j√° criados na planilha "Testes Detalhados".
3.  **Gera√ß√£o (IA):** (Apenas se for "Novo teste") Um Agente de IA (`Basic LLM Chain` + `Grok-4 Fast`) usa o contexto para gerar a bateria de testes.
4.  **Parse (Python):** Um n√≥ de C√≥digo Python (`Divide cada teste`) "quebra" o texto da IA em itens JSON individuais para cada teste.
5.  **A√ß√£o:** Salva os novos casos de teste na planilha **"Testes Detalhados"**.
6.  **Pr√≥ximo Est√°gio:** Dispara um Webhook (`Envia pra testar`) para acionar o Est√°gio 2.

### Est√°gio 2: Agente Testador de LLMs (O Simulador)
Este workflow simula as conversas.
1.  **Gatilho:** Recebe o Webhook do Est√°gio 1.
2.  **Leitura:** Puxa os casos de teste da planilha **"Testes Detalhados"**.
3.  **Loop:** Para cada caso de teste, ele inicia um loop (`Loop Over Items`).
4.  **Execu√ß√£o (IA + Ferramenta):** Um `AI Agent` (o "Test Runner") simula o usu√°rio. Ele usa uma ferramenta customizada (`agente_principal`) que √© um n√≥ de c√≥digo (JavaScript/Axios) que faz a chamada de API real para o "Agente-Alvo" que est√° sendo testado (usando o `Path do webhook` fornecido no Est√°gio 1).
5.  **Mem√≥ria:** Uma mem√≥ria (`Postgres Chat Memory`) √© usada para manter o contexto da conversa, turno ap√≥s turno, para cada teste individual.
6.  **A√ß√£o:** Ao final de cada teste, o workflow puxa o hist√≥rico completo da conversa do Postgres (`Puxa hist√≥rico`) e salva o log na planilha **"An√°lises"**.
7.  **Pr√≥ximo Est√°gio:** Ao final de *todos* os testes, dispara um Webhook (`Envia pra revis√£o`) para acionar o Est√°gio 3.

### Est√°gio 3: Agente Revisador (O Gerente de QA)
Este workflow √© o c√©rebro anal√≠tico e possui duas fases.
1.  **Gatilho:** Recebe o Webhook do Est√°gio 2.
2.  **Fase A: Revis√£o Individual**
    * L√™ todos os logs de conversa da planilha **"An√°lises"**.
    * Entra em um loop (`Loop Over Items`).
    * Para cada conversa, um `AI Agent` (o "Cr√≠tico Individual") a avalia e gera um `score` e uma `justificativa`.
    * Salva essa revis√£o individual na planilha **"Revis√£o"**.
3.  **Fase B: Relat√≥rio Consolidado (Ap√≥s o loop)**
    * L√™ *todas* as revis√µes individuais da planilha **"Revis√£o"**.
    * Agrega (`Aggregate3`) todos os dados em um √∫nico bloco de texto.
    * Envia este bloco para um `AI Agent` final (o "Gerente de QA"), que usa um modelo poderoso (`Gemini 2.5 Pro`) e um prompt massivo de "An√°lise Consolidada".
    * Este agente gera o relat√≥rio final, calculando um **Score Geral (0-100)**, analisando **Padr√µes de Erro** e **Padr√µes de Acerto**.
    * **Resultado Final:** Salva o relat√≥rio completo na planilha **"Resultado"**.

---

## 4. Como Usar (Setup Essencial)

Para que este pipeline funcione, o usu√°rio (desenvolvedor) precisa configurar o "alvo" do teste.

1.  **Tenha seu Agente-Alvo:** O seu Agente de IA (o que voc√™ quer testar) deve estar rodando e acess√≠vel atrav√©s de um **endpoint de Webhook** (POST).
2.  **Configure a Conex√£o:** O seu workflow de Agente-Alvo deve:
    * Receber o `chatInput` (a mensagem do usu√°rio) e o `sessionId` do webhook.
    * Conectar esse input ao seu pr√≥prio Agente de IA.
    * Retornar a resposta da IA no formato JSON.
3.  **Forne√ßa o Endpoint:** No formul√°rio do **Est√°gio 1**, voc√™ deve fornecer o `Path do webhook` (o final da URL do seu agente-alvo) para que o "Agente Testador" (Est√°gio 2) saiba para onde enviar as mensagens de teste.

O n√≥ `agente_principal` dentro do Est√°gio 2 √© a ferramenta que faz essa chamada (`axios.post`) para o seu webhook.

---

## 5. Ferramentas Utilizadas (Tech Stack)

* **Orquestra√ß√£o:** **n8n** (workflows, gatilhos, loops)
* **Intelig√™ncia (LLMs):**
    * **LangChain Nodes** (`AI Agent`, `Basic LLM Chain`, `Structured Output Parser`)
    * **OpenRouter** (para acesso a m√∫ltiplos modelos)
    * **Grok-4 Fast** (para gera√ß√£o r√°pida de testes e revis√£o individual)
    * **Google Gemini 2.5 Pro** (para a an√°lise consolidada final)
* **Banco de Dados:**
    * **Google Sheets** (usado como banco de dados de pipeline para mover dados entre os est√°gios)
    * **PostgreSQL** (usado para a mem√≥ria de chat (`Postgres Chat Memory`) durante a execu√ß√£o dos testes)
* **L√≥gica Customizada:**
    * **Python** (no n√≥ `Code` para parsear o output de texto do LLM)
    * **JavaScript** (no n√≥ `ToolCode` para criar a ferramenta `agente_principal` que chama o agente-alvo via `axios`)
* **Comunica√ß√£o:**
    * **Webhooks** e **HTTP Request** (para acionar os workflows em sequ√™ncia)

---

## 6. Arquivos do Workflow

* `Agente Criador de Testes.json`: Workflow do Est√°gio 1 (Gera√ß√£o de Testes).
* `Agente Testador de LLMs.json`: Workflow do Est√°gio 2 (Execu√ß√£o do Teste).
* `Agente Revisador do teste.json`: Workflow do Est√°gio 3 (An√°lise e Relat√≥rio).

# Contato
Whatsapp: 5534998557386
Instagram: eduardosousa.12
